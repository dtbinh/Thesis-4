\documentclass[12pt]{article}
\title{Multi Robot Map Joining}
\author{John Downs}
\date{August 2012}
\begin{document}
\maketitle

\begin{abstract}
The focus of the Spring semester’s work was the development of a SLAM implementation using submaps and map joining that was applicable to both single and multi robot scenarios.  Map joining SLAM can reduce the dimensionality of the problem and simplifies the data association when sharing maps between robots.  This paper covers some of the mathematical concepts such as least squares optimization and data association.  Also discussed is the relationship between traditional least squares SLAM approaches and map joining.
\end{abstract}

\section{Introduction}
\cite{cheeseman1987stochastic}.  

Early SLAM research made heavy use of Bayes Filters such as the Extended Kalman Filter and Particle Filter to create a large global map of features in a robot’s environment.  This approach worked well for small scale environments with a limited number of features, but proved to be inadequate for more expansive and feature rich environments.  As the number of landmarks increases, computation time grows and error due to linearization have a greater effect.  This was originally known as the online-SLAM problem, the idea being that a robot could use an online-SLAM algorithm to create a map in real time and use it for planning purposes.  
The online SLAM problem is contrasted with the Full SLAM problem.  In this case, the entire trajectory is retained, along with the relationship of the various poses to landmark observations.  Naively, this formulation seems to be more complex and thus was not considered a viable solution early on for real time planning.  However, the techniques developed turned out to be faster than filters in practice.  
A drawback to most Full SLAM solutions is their high dimensionality and the complexity of the implementations.  Another approach, map joining, can reduce the dimensionality of the problem and the error due to linearization, while having simpler implementations.  It is also easily adaptable to multi-robot scenarios.  When two maps share a robot pose, either through being at sequential time steps or through observation of another robot, it becomes fairly easy to find the correct coordinate frame transformations to create a global map.

\section{Technical Background}
\subsection{ Least Squares Estimates }

The key to the performance of full SLAM solutions is the least squares formulation.  The objective is to minimize the Mahalanobis distance between the predicted state and combined prediction and observation.  Mahalanobis distance is a measure of similarity for two data sets.  Applied to SLAM, this estimate uses the entire robot trajectory and observations to date to calculate a total state estimate.  Because it uses the entirety of the data available, it is called smoothing, to contrast it with filtering, which only uses the current estimate, rather than all historical data.  Smoothing finds a single state estimate that best fits all the available data.  
	The Least Squares formulation of SLAM is to minimize:
$f(x_t-1,u)^TPf(x_t-1,u) + h(z)^TRh(z) $   TODO: Check this equation! Something -
	where f()is the motion model with covariance P, and his the observation model with covariance R, uis the set of control inputs and z is the set of observations.
 Many methods exist for solving linear least squares problems, but the motion and observation models are almost never linear in practice.  When a linear least squares problem is at hand, there is always a closed form solution, thus it can be solved in a single step.  However, because SLAM is non-linear, it requires iterative methods to solve.  The reason for this is that no methods exist for solving these types of problems, so we must search for a solution.  A number of machine learning algorithms exist to solve these problems, both deterministic and stochastic.

\subsection{Map Joining}
The map joining approach to SLAM relies on the creation of submaps: local maps focused only on a subset of a trajectory and the immediately related observations.  The creation of local maps is usually accomplished by either Extended Kalman or Information Filters. Markov Chain Monte Carlo methods have also been suggested (CITE).  While these methods prove to be inconsistent, this inconsistency is only significant in large sets of observations.  By limiting their scope, linearization errors, inconsistency and complexity can be held in check.
The earliest paper I have found on map joining is [TARDOS 2002].  This describes the fundamental operations of map joining: transformation from a common observation into a global coordinate frame and feature association.  More recent formulations [C-SAM] have eliminated the need for explicit transformation through the use of a graph theoretic formulation of SLAM.  In this case, the more general term ‘map alignment’ is used over transformation.
No matter how the maps are aligned, the second step is data association.  Because of possible noise in the observation of a common landmark, alignment may not place all landmarks at the same point.  This requires a classification algorithm to be run over the map, such as k-Nearest Neighbor or Joint Compatibility Branch and Bound [TARDOS 2002].  Other classifiers can be used, but are not common in the literature.  Classification can be eliminated if noiseless identification of features is possible, such as when using cameras and unambiguous barcodes.
If there are common landmarks between the two submaps, after classification, a new state estimate is required to make sense of the matched but non-coincident features.  This is accomplished by calculating a least squares estimate of the new global map, to create a best fit ‘curve’ describing all the observations.

\subsection{ Spherical Matrices, One Step SLAM and Map Joining}
A key observation to the reduction of dimensionality in single step SLAM is the 	use of spherical covariance matrices.  An spherical matrix is defined as any matrix that is commutative with a rotation matrix.  A rotation matrix R(theta) is [cos t -sin t; sin t cos t] ← CHECK THIS  .  For all theta and any spherical matrix A, AR = RA.  
This property allows for the reformulation of the Full SLAM function into 
Formula here
It is important that the covariance matrices are also positive definite.  A matrix is positive definite if for all positive, non-zero column vectors v, v^T Mv > 0. This is to allow for methods analogous to finding the square-root of a matrix, such as Cholesky or QR factorization to be used in the solution of the least squares estimate. 
In the Automatica preprint, Dr. Huang claims that this objective function, when applied to single step SLAM, is equivalent to a one dimensional optimization problem.  Through repeated application of single step SLAM for each timestep, an approximate solution to the previous objective function can be easily found.  It is approximate because a spherical covariance matrix is used, rather than the actual covariance associated with observation uncertainty.
In On The Num of Local Minima, Dr. Huang shows that single step SLAM and map joining SLAM share the same property of having only 1 or 2 minima, one of which is global, when covariances are approximated by spherical matrices.  This provides the benefits of the reduction in linearization error due to map joining, along with the low dimensionality of single step SLAM.  Additionally, if multi-robot map joining belongs to this class of problems, map sharing can possibly become quite efficient.
In a remark from On The Number.. H notes that the covariance matrices must only be spherical, but not identical.  That is, the covariance can differ for each odometry measurement and observation.  This lends some home to the possibility that multi-robot map joining is in this class of problems.

\subsection{SLAM and Machine Learning}
	There are two sub-problems within SLAM that call for the application of machine learning techniques, landmark association and least squares optimization.  These are two separate types of problems, the former being unsupervised classification, the latter is convex optimization.
Landmark association, also known as data association, is a classification problem that uses a pair of feature maps or a map and set of observations and tries to match known landmarks with new observations.  In most cases, this is an unsupervised learning problem because the set of features can vary so greatly from map to map, it is not possible to provide examples for a supervised approach.  This is necessary for any environment where there can be ambiguity in landmarks.  While it might be possible in a lab to put barcodes on landmarks that can be recognized with a camera, in scenarios where a camera might not be available or barcoding landmarks unfeasible, landmark association is required.
The least squares portion of SLAM is non-linear and of a very high dimension.  Because of this, single step techniques such as linear regression are not applicable.  Other algorithms such as Levenberg-Marquardt, Gauss-Newton and Stochastic Gradient Descent must be used instead.  These three methods are the most popular among SLAM researchers.  
	The Gauss-Newton method is used effectively in iSAM (CITE).  It is a variation on Newton’s method for finding the minima of a function taught in elementary calculus courses but is modified to solve least squares problems.  It begins with an initial guess x_0 of a possible solution.  For an objective function f(x) and a residual function r(x), the jacobian at r(x_0) is calculated.  The jacobian is a linearization estimate of r(x) and is used for the next guess.  This process is repeated until it converges on a solution.  It is possible in certain situations to overshoot the optimum and fail to converge.  This algorithm can also fail to find a global optimum and instead converge on a local optimum.
	Gradient descent is an optimization algorithm similar to hill climbing, but rather than selecting a single element to improve, it follows the slope (or gradient) of the function towards a solution.  Like Gauss-Newton, gradient descent can get stuck in local optima.  A modification known as stochastic gradient descent can overcome this limitation.  

\section{My Experiments}
\subsection{The First Attempt}
The first attempt at implementing SLAM involved adapting the algorithm in [1] from the e-Puck to the Khepera III models for Webots.  I designed a rectangular arena with several cubes for landmarks.  The implementation was altered to move around the arena using a Braitenberg vehicle navigation strategy and to use sonar and infrared sensors rather than a camera for landmark detection.  A total of three robots were added to the Webots world.  This simulation was plagued with numerical instability.  
Whenever a robot’s wheel would move backwards, this would cause the robot position to become undefined and would result in the model disappearing from the simulation.  This was due to a bug in the code provided by [1].  After trying to resolve the issue with poor results, I decided to try a different approach.  I also worked briefly with the Mobile Robot Programming Toolbox [2], attempting to work around the simulation instability, but found the documentation on the required features was too incomplete, the author having focused on Kinect functionality instead.
\subsection{The Second Attempt}
A new review of robotics toolkits provided by other researchers resulted in two findings.  First, most implementations were in Matlab [3] [4], and those that weren’t tended to be older and poorly documented and unmaintained.  Matlab seems to be used most often because of it’s high level mathematical libraries and ease of use (as it is an interpreted language).  Second, most SLAM implementations used data files with velocity measurements and range/bearing measurements of landmarks.  This is done to abstract away the particulars of a robot and instead focus on the details of SLAM.  I then found an excellent multi robot data set that was in the correct form for doing SLAM [8].
At this point, I was able to move forward again.  The map joining approach is a continuation of the work done in [5], [6], and [7].  It first requires a sequence of submaps that share end and start poses at the transition from one to the next.  These maps can be produced by any SLAM algorithm.  I chose the EKF because it is the simplest to implement.  The initial pass was buggy and lead to very poor maps, which later affected the quality of the global map state.  This EKF implementation was later replaced by working through the tutorial in [9].  
Each map consisted of two robot poses, the last pose from the previous map (except the first map, which has the initial pose), and the final pose.  The first map was considered the ‘global map’ that all subsequent maps were added to.  The maps were combined by translating the new local map to the coordinate frame of the global map and then solving the least squares SLAM formulation provided in [6].  This least squares approach searches for a state vector that minimizes the square of observation error for each landmark.  This equation was translated into a fitness function that could be used by machine learning algorithms to find a solution.  In this case, I used a genetic algorithm using the combined local and global state vector as the gene string.  Preliminary runs would converge to a solution in less than 100 generations, but it is not clear whether this behavior will continue when used with more accurate maps.  
\subsection{More to do}
The new one step EKF SLAM implementation needs to be combined with the map joining algorithm.  This should just be a matter of refining the interface between these two components.  The map joining approach will be compared to the EKF-only maps.  The map joining algorithm needs to be made more modular so other machine learning algorithms can be applied.  Finally, data needs to be collected from the Khepera robots to see if this approach can work with unknown data association.  
For multiple robots, I need to develop a way to detect when map sharing is appropriate.  When a robot detects another one, there will be a common pose that can allow for the correct translation of the frames of reference and the same fitness function can be applied.  It is still an open question as to whether this has the same number of local minima as the situations described in [5].
Grade:
While I feel I did not make all the progress I wanted this Spring, I did complete a number of the pieces necessary to answer these questions.  I have also come to understand a number of concepts involved with SLAM that were beyond the scope of the first part of this project.  It was fair, but not outstanding work, so I feel a B would be appropriate.

\bibliography{multibot.bib}{}
\bibliographystyle{IEEE}
\end{document}
